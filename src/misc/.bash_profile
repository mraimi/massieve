alias kafka-topics='/usr/local/kafka/bin/kafka-topics.sh --list --zookeeper localhost:2181'
alias submit-job='/usr/local/spark/bin/spark-submit --class TrafficDataStreaming --master spark://ip-172-31-0-6:7077 --jars target/scala-2.10/price_data-assembly-1.0.jar target/scala-2.10/price_data_2.10-1.0.jar'
alias start-producer='~/opt/realtimeAnomalies/src/main/producer/spawn_kafka_streams.sh 23.22.195.205 4 k1'
alias ll='ls -la --block-size=M'
alias kafka-clear='/usr/local/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --alter --topic traffic_data --config retention.ms=1000'
alias kafka-restore='/usr/local/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --alter --topic traffic_data --config retention.ms=86400000'
alias hdfs='/usr/local/hadoop/bin/hdfs'
alias spark-shell='/usr/local/spark/bin/spark-shell  --master spark://ip-172-31-0-6:7077 --jars target/scala-2.10/price_data-assembly-1.0.jar target/scala-2.10/price_data_2.10-1.0.jar'
alias test-data-url='hdfs://ec2-23-22-195-205.compute-1.amazonaws.com:9000/data/kddcup.testdata.unlabeled'
alias start-clustering='/usr/local/spark/bin/spark-submit --class TrafficDataStreaming --master spark://ip-172-31-0-6:7077 --jars target/scala-2.10/price_data-assembly-1.0.jar target/scala-2.10/price_data_2.10-1.0.jar'
export hdfs_root='hdfs://ec2-23-22-195-205.compute-1.amazonaws.com:9000/'
